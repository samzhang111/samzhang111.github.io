---
layout: post
title: xargs args
date: 2015-10-05 20:51:00
---

{{page.title}}
==============
{{page.date}}

When downloading files in parallel with
[xargs](http://man7.org/linux/man-pages/man1/xargs.1.html) and
wget, I used this command:

```
 xargs -P16 wget < websites.txt
```

This (supposedly) tells xargs to spin up to 16 wget processes, and
distribute the inputs across them. However, I was only seeing two
processes. I assumed that since I was running on an EC2 micro instance,
I simply ran out of memory for more. I should have checked this fact,
in `top` perhaps, and noticing that neither xargs nor wget were
particularly taxing my system, would have revisited the flags (hopefully).

Then, by reading carefully, I could have seen this line:

```
Use the -n option with -P; otherwise chances are[*] that only one exec will be done.
```

It shows me right to copy code directly from[strangers with blogs on
the Internet](http://www.boyter.org/2011/02/wget-xargs/).

